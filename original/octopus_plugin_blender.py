# -*- coding: utf-8 -*-
"""SDXL10_octopusAPI_orbit_camera_linux.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P6fWDskpJfEc7hNM9IgUPz8dL_wVB44V
"""

import os

### BEGIN USER EDITABLE SECTION ###
dependencies = [
    "pip install -q flask pyngrok",
    "pip install -q joblib",
    "pip install -q uuid",
    "pip install -q gdown",
    "apt install libgl1-mesa-glx"
]

for command in dependencies:
    os.system(command)

import gdown

bpy_url = "https://drive.google.com/u/0/uc?id=1UNPCJVp-UrisPbQMAsVHhTQz92qTW86f&export=download"
bpy_package = "bpy.whl"
gdown.download(bpy_url, bpy_package, quiet=False)
os.system("pip install bpy-3.6.3rc0-cp310-cp310-manylinux_2_35_x86_64.whl")

config_str = '''
{
    "device_map": {
     "cuda:0": "10GiB",
     "cpu": "30GiB"
     },
     "models": [
         {
             "key": "10133_integration.blend",
             "name": "blender_model",
             "access_token": "https://drive.google.com/uc?id=1UAycFFA3UvSCVBwyTMZ12oD9sDiRancO&export=download"
         }
     ],
     "functions": [
         {
             "name": "orbit-camera",
             "description": "Renders an image showing the machine from given angle with aditional control of the zoom and tilt",
             "parameters": {
                 "type": "object",
                 "properties": {
                     "position":{
                         "type": "int",
                         "description": "the value from 1-100 representing 360 degree rotation arround the machine, it start on the right center of the machine"
                     },
                     "tilt":{
                         "type": "string",
                         "enum": ["up", "center", "down"],
                         "description": "value that controls the camera rotation in x axis, when the camera is tilted down machine is shown from top"
                     },
                     "zoom":{
                         "type": "string",
                         "enum": ["far", "middle", "close"],
                         "description": "value that controls the camera zoom, it can be used to look at the machine closer or to see more of it on the same render"
                     },
                     "resolution":{
                         "type": "string",
                         "enum": ["full-hd", "4k"],
                         "description": "allows to select resolution desired by user, 4k resolution helps to see finer detail on the rendered image"
                     }
                 },
                 "required": ["position"]
             },
             "input_type": "json",
             "return_type": "image/png"
         },
         {
             "name": "find-part",
             "description": "Renders an image showing given part in full view, with additional control of hidding all parts between the part and the camera",
             "parameters": {
                 "type": "object",
                 "properties": {
                     "part":{
                         "type": "string",
                         "description": "The part name to be found and shown on render"
                     },
                     "clip":{
                         "type": "boolean",
                         "description": "if set to True all parts befor the camera will be hidden on the reneder"
                     },
                     "resolution":{
                         "type": "string",
                         "enum": ["full-hd", "4k"],
                         "description": "allows to select resolution desired by user, 4k resolution helps to see finer detail on the rendered image"
                     }
                 },
                 "required": ["part"]
             },
             "input_type": "json",
             "return_type": "image/png"
         }

     ]
 }
'''

import bpy  #Starts Blender instance
import math
import mathutils

class BlenderModelManager:
    def __init__(self, key, name, token, gpu_name = 'NVIDIA GeForce RTX 4090'):
        extension = key.split(".")[-1]
        file_name = f"{name}.{extension}"
        gdown.download(token, output=file_name, quiet=False)

        bpy.ops.wm.open_mainfile(filepath=file_name)
        bpy.context.preferences.addons['cycles'].preferences.compute_device_type = 'OPTIX'
        bpy.context.preferences.addons['cycles'].preferences.refresh_devices()
        bpy.context.preferences.addons['cycles'].preferences.devices[gpu_name].use = True
        bpy.context.scene.cycles.device = 'GPU'

        self.orbit_camera_object = bpy.data.objects.get("Orbit_camera")
        self.orbit_curve_object = bpy.data.objects.get("Orbit_curve")
        self.part_camera_object = bpy.data.objects.get("Part_camera")

        print("Blender model loaded")
    
    def orbit_inference(self, position, tilt, zoom, resolution, output_filename):
        self._orbit(position, tilt, zoom)
        self._generate_image(self.orbit_camera_object, resolution, output_filename)
    
    def find_part_inference(self, part_name, resolution, output_filename, clip=False):
        self._find_part(self.part_camera_object, part_name,clip)
        self._generate_image(self.part_camera_object, resolution, output_filename)

    def _orbit(self, position:int, tilt, zoom):
        self._change_tilt(tilt)
        self._change_zoom(zoom)
        self._change_position(position)
    
    def _find_part(self,camera, part_name, clip):
        distance = self._copy_object_center_to_camera(part_name, camera)
        if clip == True:
            self._set_camera_clip(camera, distance * 0.9)
        else:
            self._set_camera_clip(camera, 0.1)

    def _generate_image(self, camera, resolution="full-hd", filename="output"):
        assert camera and camera.type == "CAMERA", "given object for renderign an image is not a camera object"
        x_res_dict = {
        "full-hd" : 1920,
        "4k" : 3840
        }
        y_res_dict = {
        "full-hd" : 1080,
        "4k" : 2160
        }
        bpy.context.scene.render.resolution_x = x_res_dict[resolution]
        bpy.context.scene.render.resolution_y = y_res_dict[resolution]
        bpy.context.scene.render.image_settings.file_format = 'PNG'
        bpy.context.scene.render.filepath = f"//{filename}.png"  # Relative to blend file

        bpy.context.scene.camera = camera
        bpy.ops.render.render(write_still=True)

    def _change_tilt(self, tilt="center"):
        assert self.orbit_curve_object and self.orbit_curve_object.type == "CURVE", "given object for tilt manipulation is not a curve object"
        curve = self.orbit_curve_object.data
        
        tilt_dict = {
            "down" : 25.0,
            "center" : 5.0,
            "up"  : -5.0
        }

        # Access the control points of the curve
        points = curve.splines[0].bezier_points
        
        # Modify the tilt of control points
        for point in points:
            point.tilt = math.radians(tilt_dict[tilt])

    def _change_zoom(self, zoom="middle"):
        assert self.orbit_camera_object and self.orbit_camera_object.type == "CAMERA", "given object for zoom manipulation is not a camera object"
        zoom_dict = {
            "far" : 9,
            "middle" : 22,
            "close" : 28
        }
        self.orbit_camera_object.data.lens = zoom_dict[zoom]

    def _change_position(self, position):
        follow_path_constraint = self.orbit_camera_object.constraints.get("Follow Path")
        assert follow_path_constraint and follow_path_constraint.type == 'FOLLOW_PATH', "follow path constraint not found for given object for position manipulation"
        follow_path_constraint.offset = position

    def _find_geometric_center(self, object_name):
        # Find the object by name
        target_object = bpy.data.objects.get(object_name)

        if target_object is not None:
            # Get the object's bounding box
            bbox = [target_object.matrix_world @ v.co for v in target_object.data.vertices]

            # Calculate the geometric center
            geometric_center = sum(bbox, mathutils.Vector()) / len(bbox)

            return geometric_center
        else:
            print(f"Object with name '{object_name}' not found.")
            return None

    def _set_camera_clip(self, camera_name, near_clip):
        # Find the camera by name
        camera = bpy.data.cameras.get(camera_name)

        if camera is not None:
            # Set the near and far clip values
            camera.clip_start = near_clip
        else:
            print(f"Camera with name '{camera_name}' not found.")

    def _copy_object_center_to_camera(self, object_name, camera):
        # Find the object by name
        target_object = bpy.data.objects.get(object_name)

        if target_object is not None and camera is not None:
            # Get the X coordinate of the object's center
            coordinate = self._find_geometric_center(object_name)
            x_coordinate = coordinate.x

            # Set the camera's X coordinate of location
            camera.location.x = x_coordinate

            # Calculate the camera's distance to the object's center
            distance_to_object = (camera.location - coordinate).length

            #Calculate focal length to keep the object in the frame
            sensor_width = camera.data.sensor_width/1000
            sensor_height = camera.data.sensor_height/1000
            object_width = target_object.dimensions.x
            object_height = target_object.dimensions.z
            desired_focal_length_width = ((distance_to_object*sensor_width) / object_width) * 1000
            desired_focal_length_height = ((distance_to_object*sensor_height) / object_height) * 1000

            # Use the smaller of the two focal lengths to ensure the entire object fits in the frame
            desired_focal_length = min(desired_focal_length_width, desired_focal_length_height)

            # Set the camera's focal length
            camera.data.lens = desired_focal_length

            #tilt the camera to look at the object
            direction_to_target = coordinate - camera.location
            tilt_angle = math.atan2(direction_to_target.z, direction_to_target.y)
            camera.rotation_euler.x= tilt_angle+math.radians(90)

            # Update the scene to refresh the camera view
            bpy.context.view_layer.update()

            return distance_to_object
        else:
            print("Wrong names given for part or camera")
try:
    import google.colab
    # Change to /content directory
    os.chdir('/content')
    print("Changed directory to /content")
except ImportError:
    print("Not running in Colab")

### END USER EDITABLE SECTION ###

import json
import base64
from io import BytesIO
from flask import Flask, request, jsonify
import uuid
import time

config = json.loads(config_str)
app = Flask(__name__)

class ModelManager:
    def __init__(self, config):
        self.config = config
        self.models = {}
        self.device = self.select_device()

    def select_device(self):
        device_map = self.config.get('device_map', {})
        available_devices = list(device_map.keys())
        return available_devices[0] if available_devices else "cpu"

    def setup(self):
        self.models.clear()

        # Loading models from configuration
        for model_info in self.config["models"]:
            model_key = model_info["key"]
            model_name = model_info["name"]
            model_access_token = model_info["access_token"]
            try:
                ### BEGIN USER EDITABLE SECTION ###
                model = BlenderModelManager(model_key,model_name, model_access_token)
                self.models[model_name] = model
                ### END USER EDITABLE SECTION ###
            except Exception as e:
                print(f"Error loading model {model_name}: {e}")

    def infer_orbit(self, parameters):
        try:
            ### BEGIN USER EDITABLE SECTION ###
            output_filename = str(uuid.uuid4())
            blender_model = self.models["blender_model"]

            print("orbit-inference")
            blender_model.orbit_inference(parameters['position'], parameters['tilt'], parameters['zoom'], parameters['resolution'], output_filename)

            while os.path.exists(output_filename+".png") == False:
                time.sleep(5)

            return output_filename+".png"
            ### END USER EDITABLE SECTION ###
        except Exception as e:
            print(f"Error during inference: {e}")
            return None

    def infer_part(self, parameters):
        try:
            ### BEGIN USER EDITABLE SECTION ###
            output_filename = str(uuid.uuid4())
            blender_model = self.models["blender_model"]

            print("part-inference")
            blender_model.find_part_inference(parameters['part'], parameters['resolution'], output_filename, parameters['clip'])

            while os.path.exists(output_filename+".png") == False:
                time.sleep(5)

            return output_filename+".png"
        ### END USER EDITABLE SECTION ###
        except Exception as e:
            print(f"Error during inference: {e}")
            return None


model_manager = ModelManager(config)

@app.route('/v1/setup', methods=['POST'])
def setup():
    model_manager.setup()
    return jsonify({"status": "models loaded successfully", "setup": "Performed"}), 201

@app.route('/v1/orbit-camera', methods=['POST'])
def generic_route():
    function_config = config["functions"][0]

    if not function_config:
        return jsonify({"error": "Invalid endpoint"}), 404

    if function_config["input_type"] != "json":
        return jsonify({"error": f"Unsupported input type {function_config['input_type']}"}), 400

    data = request.json
    parameters = {k: data[k] for k in function_config["parameters"]["properties"].keys() if k in data}

    result = model_manager.infer_orbit(parameters)
    if result:
        file = open(result, mode='rb')
        fcontent = file.read()
        file.close()
        return app.response_class(fcontent, content_type=function_config["return_type"]), 201
    else:
        return jsonify({"error": "Error during inference"}), 500

@app.route('/v1/find-part', methods=['POST'])
def generic_route_1():
    function_config = config["functions"][1]

    if not function_config:
        return jsonify({"error": "Invalid endpoint"}), 404

    if function_config["input_type"] != "json":
        return jsonify({"error": f"Unsupported input type {function_config['input_type']}"}), 400

    data = request.json
    parameters = {k: data[k] for k in function_config["parameters"]["properties"].keys() if k in data}

    result = model_manager.infer_part(parameters)
    if result:
        file = open(result, mode='rb')
        fcontent = file.read()
        file.close()
        return app.response_class(fcontent, content_type=function_config["return_type"]), 201
    else:
        return jsonify({"error": "Error during inference"}), 500

@app.errorhandler(Exception)
def handle_exception(e):
    # Generic exception handler
    return jsonify(error=str(e)), 500

import threading
from pyngrok import ngrok
import time

# Start the Flask server in a new thread
app.run(threaded=False)

# Set up Ngrok to create a tunnel to the Flask server
public_url = "http://127.0.0.1:5002"
public_url = ngrok.connect(5000).public_url
#public_url = "http://127.0.0.1:5002"

function_names = [func['name'] for func in config["functions"]]

print(f" * ngrok tunnel \"{public_url}\" -> \"http://127.0.0.1:{5000}/\"")

# Loop over function_names and print them
for function_name in function_names:
   time.sleep(5)
   print(f'Endpoint here: {public_url}/{function_name}')

